# GraTeD_MLP
This is a code implementation of a research paper namely GraTeD MLP distillation which demonstrates how to distil Graph Transformer model to vanilla mlp while leaverging the benefits of the graph transformer with the complex data type ie its Attention Matrix :)
